{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import packs and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sodapy in /home/dsc/anaconda3/lib/python3.7/site-packages (2.1.0)\n",
      "Requirement already satisfied: requests>=2.20.0 in /home/dsc/anaconda3/lib/python3.7/site-packages (from sodapy) (2.25.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/dsc/anaconda3/lib/python3.7/site-packages (from requests>=2.20.0->sodapy) (2021.5.30)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/dsc/anaconda3/lib/python3.7/site-packages (from requests>=2.20.0->sodapy) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/dsc/anaconda3/lib/python3.7/site-packages (from requests>=2.20.0->sodapy) (1.24.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/dsc/anaconda3/lib/python3.7/site-packages (from requests>=2.20.0->sodapy) (2.8)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/dsc/anaconda3/lib/python3.7/site-packages (4.6.3)\n",
      "Requirement already satisfied: lxml in /home/dsc/anaconda3/lib/python3.7/site-packages (4.2.5)\n",
      "Requirement already satisfied: requests in /home/dsc/anaconda3/lib/python3.7/site-packages (2.25.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/dsc/anaconda3/lib/python3.7/site-packages (from requests) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/dsc/anaconda3/lib/python3.7/site-packages (from requests) (2.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/dsc/anaconda3/lib/python3.7/site-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/dsc/anaconda3/lib/python3.7/site-packages (from requests) (1.24.1)\n"
     ]
    }
   ],
   "source": [
    "#Install all packs needed to download data from Pollutant website Catalonia's government (sodapy) and web scrapping from meteo web\n",
    "! pip install sodapy\n",
    "! pip install beautifulsoup4\n",
    "! pip install lxml\n",
    "! pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries required\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sodapy import Socrata\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import pickle \n",
    "import streamlit as st \n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE: I tried to use web scrapping in order to get data, but I attempt in 2 different web sites,and I highlighted that every few hours, position of data change location, doing not ppossible to fix data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Download Pollutant DATA from web page by downloading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Current day\n",
    "now = datetime.now()\n",
    "\n",
    "#In order to get enough data, if time is prior to midday, data is got from prior day, if not so, data is got from current day. \n",
    "#The aim of this is to get minimum 12 hours dataset.\n",
    "\n",
    "if now.strftime('%H')>='12':\n",
    "    fecha = now\n",
    "else:\n",
    "    fecha = now - timedelta(days=1)\n",
    "    \n",
    "fecha=fecha.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-21 14:03:05.691 WARNING root: Requests made without an app_token will be subject to strict throttling limits.\n"
     ]
    }
   ],
   "source": [
    "#Download data info from web. It is not needed token because we will download data once.\n",
    "socrata_domain = \"analisi.transparenciacatalunya.cat\"\n",
    "socrata_dataset_identifier = \"tasf-thgu\"\n",
    "#socrata_token = os.environ.get(\"None\") --> not needed, but just in case, here we have the sentence to include it.\n",
    "\n",
    "client = Socrata(socrata_domain, None)\n",
    "#print(\n",
    "#    \"Domain: {domain:}\\nSession: {session:}\\nURI Prefix: {uri_prefix:}\".format(\n",
    "#        **client.__dict__\n",
    "#    )\n",
    "#)\n",
    "\n",
    "metadata = client.get_metadata(socrata_dataset_identifier)\n",
    "#[x[\"name\"] for x in metadata[\"columns\"]]\n",
    "\n",
    "results = client.get(socrata_dataset_identifier,\n",
    "                    limit=100000, \n",
    "                    nom_estacio=\"Tarragona (Bonavista)\",\n",
    "                    data=fecha)    \n",
    "    \n",
    "dfA = pd.DataFrame.from_dict(results);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's select features interested\n",
    "dfB=dfA.drop(['codi_eoi', 'nom_estacio', 'data', 'magnitud', 'unitats',\n",
    "       'tipus_estacio', 'area_urbana', 'codi_ine', 'municipi', 'codi_comarca',\n",
    "       'nom_comarca', 'altitud', 'latitud',\n",
    "       'longitud', 'geocoded_column'],axis=1)\n",
    "#Let's create an average feature \n",
    "ave = dfB.loc[: , \"h01\":]\n",
    "ave = ave.astype(float)\n",
    "dfB['0'] = ave.mean(axis=1)\n",
    "# Simplified dataframe \n",
    "dfC = dfB[['contaminant','0']]\n",
    "#Crete a pivot table to adecuate the format\n",
    "tableA = dfC.pivot_table(columns='contaminant', aggfunc=np.sum)\n",
    "#Let's select interested pollutant features \n",
    "tableB=tableA[['NO2','PM2.5','PM10']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Download Meteorological DATA from web page by downloading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "executionInfo": {
     "elapsed": 470541,
     "status": "ok",
     "timestamp": 1626259419751,
     "user": {
      "displayName": "Alberto Jimenez",
      "photoUrl": "",
      "userId": "15710970773213639218"
     },
     "user_tz": -120
    },
    "id": "FE9FH-doQcp_",
    "outputId": "23b3acfa-1c79-4034-9819-dc7886ed1801"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-21 14:03:06.275 WARNING root: Requests made without an app_token will be subject to strict throttling limits.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domain: analisi.transparenciacatalunya.cat\n",
      "Session: <requests.sessions.Session object at 0x7f8d7eea6850>\n",
      "URI Prefix: https://\n"
     ]
    }
   ],
   "source": [
    "socrata_domain = \"analisi.transparenciacatalunya.cat\"\n",
    "socrata_dataset_identifier = \"nzvn-apee\"\n",
    "#socrata_token = os.environ.get(\"None\")\n",
    "\n",
    "client = Socrata(socrata_domain, None)\n",
    "print(\n",
    "    \"Domain: {domain:}\\nSession: {session:}\\nURI Prefix: {uri_prefix:}\".format(\n",
    "        **client.__dict__\n",
    "    )\n",
    ")\n",
    "\n",
    "#metadata = client.get_metadata(socrata_dataset_identifier)\n",
    "#[x[\"name\"] for x in metadata[\"columns\"]]\n",
    "\n",
    "results = client.get(socrata_dataset_identifier,\n",
    "                    limit=775,\n",
    "                    codi_estacio=\"XE\",\n",
    "                    order='data_lectura DESC')\n",
    "                     \n",
    "df = pd.DataFrame.from_dict(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "363_7wcIQcqO"
   },
   "outputs": [],
   "source": [
    "#Data object should be modified to datetime, to later on be merged with Pollutant data.\n",
    "df['data_lectura'] = pd.to_datetime(df['data_lectura'], dayfirst=True)\n",
    "#Let's reduce dataframe to columns desired: date, feature and value\n",
    "df1=df[['data_lectura','codi_variable','valor_lectura']]\n",
    "#Let's generate a pivot table to allocate meteorological features in columns as features and date samples as rows\n",
    "table = df1.pivot_table(index='data_lectura', columns='codi_variable', aggfunc=np.sum,)\n",
    "#Reduce a unique column row\n",
    "table = pd.DataFrame(table.to_records())\n",
    "#Date is sorted by ascending value\n",
    "table = table.sort_values(['data_lectura'],ascending=True)\n",
    "#Relabel columns\n",
    "table.columns = ['data_lectura','1','2','3','30','31','32','33','34','35','36','40','42','44','50','51','72']\n",
    "#Features values should be transformed to float to be interpreted mathematically\n",
    "table[['1','2','3','30','31','32','33','34','35','36','40','42','44','50','51','72']] = table[['1','2','3','30','31','32','33','34','35','36','40','42','44','50','51','72']].astype(float)\n",
    "#Table is grouped by daily measures in order to be consistency with Pollutant dataset. It means, daily samples\n",
    "table1 = table.groupby(table['data_lectura'].dt.month).mean()\n",
    "table2 = table1.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-21 14:03:06.963 WARNING root: Requests made without an app_token will be subject to strict throttling limits.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domain: analisi.transparenciacatalunya.cat\n",
      "Session: <requests.sessions.Session object at 0x7f8d7ef13d90>\n",
      "URI Prefix: https://\n"
     ]
    }
   ],
   "source": [
    "#Features above were downloaded as label numbered, so let's rename the features with Features label accordingly.\n",
    "socrata_domain = \"analisi.transparenciacatalunya.cat\"\n",
    "socrata_dataset_identifier = \"4fb2-n3yi\"\n",
    "#socrata_token = os.environ.get(\"None\")\n",
    "\n",
    "client = Socrata(socrata_domain, None)\n",
    "print(\n",
    "    \"Domain: {domain:}\\nSession: {session:}\\nURI Prefix: {uri_prefix:}\".format(\n",
    "        **client.__dict__\n",
    "    )\n",
    ")\n",
    "\n",
    "results = client.get(socrata_dataset_identifier)    \n",
    "v = pd.DataFrame.from_dict(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 855
    },
    "executionInfo": {
     "elapsed": 235,
     "status": "ok",
     "timestamp": 1626260022273,
     "user": {
      "displayName": "Alberto Jimenez",
      "photoUrl": "",
      "userId": "15710970773213639218"
     },
     "user_tz": -120
    },
    "id": "9HTN42d5QcqK",
    "outputId": "ae8b51fd-6c1e-435c-b44c-be39a3952a92"
   },
   "outputs": [],
   "source": [
    "#Dataframe creation\n",
    "v1 = pd.DataFrame(v.to_records())\n",
    "#Let's create a Dictionary to relabel columns\n",
    "dict = pd.Series(v1.codi_variable.values,index=v1.nom_variable).to_dict()\n",
    "#Let's sort the dictionary\n",
    "sorted_dict = sorted(dict.items(), key=operator.itemgetter(1), reverse=False)\n",
    "#Rename columns with feature labels\n",
    "table2.columns = ['data_lectura','Pressió atmosfèrica màxima',\n",
    " 'Pressió atmosfèrica mínima',\n",
    " 'Humitat relativa màxima',\n",
    " 'Velocitat del vent a 10 m (esc.)',\n",
    " 'Direcció de vent 10 m (m. 1)',\n",
    " 'Temperatura',\n",
    " 'Humitat relativa',\n",
    " 'Pressió atmosfèrica',\n",
    " 'Precipitació',\n",
    " 'Irradiància solar global',\n",
    " 'Temperatura màxima',\n",
    " 'Temperatura mínima',\n",
    " 'Humitat relativa mínima',\n",
    " 'Ratxa màxima del vent a 10 m',\n",
    " 'Direcció de la ratxa màxima del vent a 10 m',\n",
    " 'Precipitació màxima en 1 minut']\n",
    "table3 = table2[['Velocitat del vent a 10 m (esc.)', 'Temperatura', 'Pressió atmosfèrica',]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Join datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "table3.insert(0,\"orden\",['0'],True)\n",
    "tableB.insert(0,\"orden\",['0'],True)\n",
    "merged = pd.merge(left=tableB, right=table3, how='left', left_on='orden', right_on='orden')\n",
    "porfin=merged.drop(['orden'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open('FrontEnd_docs_related/aplication.pkl', 'rb') \n",
    "pipe_svc = pickle.load(pickle_in) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Define App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-21 14:03:07.975 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /home/dsc/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "#Let's create a FrontEnd where the user can have an overview about Evolution of the 4 main Pollutants from period 2010-2020, and Predict if PM2.5 system Alert and meausures involved will be activated tomorrow. \n",
    "st.title('Pollutant Evolution and Preventive Alert System')\n",
    "st.write('This web app allows you to know Pollutant Evolution from 2010 to 2020 and PM2.5 24h prediction as Preventive Sytem Alert')\n",
    "\n",
    "\n",
    "\n",
    "st.header('Pollutant Evolution')\n",
    "st.write('This section allows you to know Pollutant Evolution from 2010 to 2020 from pollutant selected')\n",
    "st.text('Please, select Pollutant desired in side to see its Evolution graph during last 10 years')\n",
    "\n",
    "st.sidebar.title(\"Pollutant\")\n",
    "select = st.sidebar.selectbox('Select Pollutant',(['PM2.5'],['PM10'],['NO2'],['NOx'],['NO'],['H2S'],['SO2']))\n",
    "\n",
    "                              \n",
    "if select == ['PM2.5']:\n",
    "        st.image(Image.open('FrontEnd_docs_related/PM2.5.jpg'))\n",
    "        st.text('PM2.5 Evolution: Downward trend in average annual values obtained for pollutant PM2,5 during last years.') \n",
    "        st.text('The worst results were registered in 2015')\n",
    "elif select == ['PM10']:\n",
    "        st.image(Image.open('FrontEnd_docs_related/PM10.jpg'))\n",
    "        st.text('PM10 Evolution: Stable results with an upward trend in average annual values obtained for pollutant PM10 in recent years.')\n",
    "        st.text('The improvement in 2020 was due to the influence of the Covid-19 pandemic')\n",
    "elif select == ['H2S']:\n",
    "        st.image(Image.open('FrontEnd_docs_related/H2S.jpg'))\n",
    "        st.text('H2S Evolution: Downward trend in average annual values obtained for pollutant H2S during last years.')\n",
    "        st.text('The worst results were registered in 2015')\n",
    "elif select == ['NO']:\n",
    "        st.image(Image.open('FrontEnd_docs_related/NO.jpg'))\n",
    "        st.text('NO Evolution: Stable results got for pollutant NO during last years')\n",
    "elif select == ['NOx']:\n",
    "        st.image(Image.open('FrontEnd_docs_related/NOx.jpg'))\n",
    "        st.text('NOx Evolution: Stable results got for pollutant NOx during last years')\n",
    "elif select == ['SO2']:\n",
    "        st.image(Image.open('FrontEnd_docs_related/SO2.jpg'))\n",
    "        st.text('SO2 Evolution: Stable results with an upward trend in average annual values obtained for pollutant SO2 in recent years.')\n",
    "        st.text('The improvement in 2020 was due to the influence of the Covid-19 pandemic')\n",
    "else:\n",
    "        st.image(Image.open('FrontEnd_docs_related/NO2.jpg'))\n",
    "        st.text('NO2 Evolution: Stable results got for pollutant NO2 during last years')\n",
    "\n",
    "    \n",
    "        \n",
    "\n",
    "st.header('Preventive System PM2.5 Alert')\n",
    "st.write('This section allows you to predict PM2.5 24h forecast by automatically data requiered.')\n",
    "st.text('Please, select data impute method to predict PM2.5 24h forecast')\n",
    "\n",
    "st.sidebar.title(\"Predict impute method\")\n",
    "select1 = st.sidebar.selectbox('Select method',(['Automatic'],['Manual']))\n",
    "\n",
    "st.text('Preventive Sytem Alert is Activated when:')\n",
    "st.text('     - average PM2,5 today feature exceeed threshold 25 micrograms/m3')\n",
    "st.text('     - prediction at 24h does not improve the results')\n",
    "\n",
    "\n",
    "\n",
    "if select1 == ['Manual']:\n",
    "    PM25 =  st.number_input(\"PM2.5 (micrograms/m3):\")\n",
    "    NO2 = st.number_input(\"NO2 (micrograms/m3):\")\n",
    "    PM10 =  st.number_input(\"PM10 (micrograms/m3):\")\n",
    "    Pressio_atmosferica = st.number_input(\"Atmospheric pressure (hPa):\")\n",
    "    Temperatura = st.number_input(\"Temperature (ºC):\")\n",
    "    Velocitat = st.number_input(\"Wind spped (m/s):\")\n",
    "        \n",
    "    features = {'PM2.5': PM25, 'PM10': PM10,'NO2':NO2,'Pressió atmosfèrica': Pressio_atmosferica,'Temperatura': Temperatura,'Velocitat del vent a 10 m (esc.)': Velocitat}\n",
    "    X_user  = pd.DataFrame([features])\n",
    "        \n",
    "    submit =st.button('Predict')\n",
    "        \n",
    "    if submit:   \n",
    "        \n",
    "        prediction = pipe_svc.predict(X_user)\n",
    "            \n",
    "        if prediction == 1 and PM25>=20:\n",
    "            st.write('Alert activated')\n",
    "            st.text('Countermeasures to be followed by:')\n",
    "            st.write(' - Citizen awareness:')\n",
    "            st.write('        -To reduce displacements with a private vehicle (use Public transport, trips on foot or by bicycle)')\n",
    "            st.write(' - Municipalities city hall:')\n",
    "            st.write('        -Local media diffusion campaigns to explain the warning situation')\n",
    "            st.write('        -Do not allow the burning of vegetation and enhance the management of plant residues, such as crushing or collection for its composting')\n",
    "            st.write('        -Suspended construction work')\n",
    "            st.write(' - Industry:')\n",
    "            st.write('        -Do not perform processes such as start up or set up not indispensable, if they can be delayed')\n",
    "        else:\n",
    "            st.write('No Alert')\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "else:\n",
    "    \n",
    "    \n",
    "    X_user1  = pd.DataFrame(porfin)\n",
    "    st.table(porfin)  \n",
    "\n",
    "    submit =st.button('Predict')\n",
    "\n",
    "    if submit:   \n",
    "        \n",
    "        prediction = pipe_svc.predict(X_user1)\n",
    "            \n",
    "        if prediction == 1 and int(X_user1['PM2.5'])>=20:\n",
    "            st.write('Alert activated')\n",
    "            st.text('Countermeasures to be followed by:')\n",
    "            st.write(' - Citizen awareness:')\n",
    "            st.write('        -To reduce displacements with a private vehicle (use Public transport, trips on foot or by bicycle)')\n",
    "            st.write(' - Municipalities city hall:')\n",
    "            st.write('        -Local media diffusion campaigns to explain the warning situation')\n",
    "            st.write('        -Do not allow the burning of vegetation and enhance the management of plant residues, such as crushing or collection for its composting')\n",
    "            st.write('        -Suspended construction work')\n",
    "            st.write(' - Industry:')\n",
    "            st.write('        -Do not perform processes such as start up or set up not indispensable, if they can be delayed')\n",
    "        else:\n",
    "            st.write('No Alert')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Launch App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook FrontEnd.ipynb to script\n",
      "[NbConvertApp] Writing 12749 bytes to FrontEnd.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert   --to script FrontEnd.ipynb\n",
    "!awk '!/ipython/' FrontEnd.py >  temp.py && mv temp.py app.py && rm FrontEnd.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
      "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://10.0.2.15:8501\u001b[0m\n",
      "\u001b[0m\n",
      "2021-07-21 14:03:10.651 Requests made without an app_token will be subject to strict throttling limits.\n",
      "2021-07-21 14:03:11.125 Requests made without an app_token will be subject to strict throttling limits.\n",
      "Domain: analisi.transparenciacatalunya.cat\n",
      "Session: <requests.sessions.Session object at 0x7f1fd6d4e590>\n",
      "URI Prefix: https://\n",
      "2021-07-21 14:03:11.856 Requests made without an app_token will be subject to strict throttling limits.\n",
      "Domain: analisi.transparenciacatalunya.cat\n",
      "Session: <requests.sessions.Session object at 0x7f1fc17e8490>\n",
      "URI Prefix: https://\n",
      "2021-07-21 14:03:17.387 Requests made without an app_token will be subject to strict throttling limits.\n",
      "2021-07-21 14:03:17.882 Requests made without an app_token will be subject to strict throttling limits.\n",
      "Domain: analisi.transparenciacatalunya.cat\n",
      "Session: <requests.sessions.Session object at 0x7f1fc062f2d0>\n",
      "URI Prefix: https://\n",
      "2021-07-21 14:03:18.644 Requests made without an app_token will be subject to strict throttling limits.\n",
      "Domain: analisi.transparenciacatalunya.cat\n",
      "Session: <requests.sessions.Session object at 0x7f1fa6b95e10>\n",
      "URI Prefix: https://\n",
      "2021-07-21 14:03:23.841 Requests made without an app_token will be subject to strict throttling limits.\n",
      "2021-07-21 14:03:24.235 Requests made without an app_token will be subject to strict throttling limits.\n",
      "Domain: analisi.transparenciacatalunya.cat\n",
      "Session: <requests.sessions.Session object at 0x7f1fa6595990>\n",
      "URI Prefix: https://\n",
      "2021-07-21 14:03:24.907 Requests made without an app_token will be subject to strict throttling limits.\n",
      "Domain: analisi.transparenciacatalunya.cat\n",
      "Session: <requests.sessions.Session object at 0x7f1fa65bec90>\n",
      "URI Prefix: https://\n"
     ]
    }
   ],
   "source": [
    "! streamlit run app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
